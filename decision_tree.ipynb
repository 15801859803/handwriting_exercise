{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#本次尝试使用python实现决策树算法\n",
    "\n",
    "def entropy(y) -> float:\n",
    "    \"\"\"\n",
    "    param data: A np.array which contains the attribute y\n",
    "    \"\"\"\n",
    "    gross = len(y)\n",
    "    all_attr = np.unique(y)\n",
    "    attributes = len(all_attr)\n",
    "    freq = np.zeros((1,attributes))\n",
    "    \n",
    "    for i in range(attributes):\n",
    "        counts = len(y[y==all_attr[i]])\n",
    "        freq[0,i] = counts\n",
    "    \n",
    "    p = freq / gross\n",
    "    lnp = np.log(p)\n",
    "    entropy = -1 * np.sum(p * lnp)\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "def conditional_entropy(feature,label) -> float:\n",
    "    \"\"\"\n",
    "    param feature : an m*1 np.array which contains one feature with different numbers\n",
    "    param label : an m*1 np.array ,the Y\n",
    "    \"\"\"\n",
    "    entropy_dict = {}\n",
    "    \n",
    "    for value in np.unique(feature):\n",
    "        entropy_dict[value] = label[np.where(feature==value)]\n",
    "    \n",
    "    total_len = len(label)\n",
    "    con_ent = 0.0\n",
    "    \n",
    "    for value in entropy_dict.values():\n",
    "        p = len(value) / total_len * entropy(value)\n",
    "        con_ent += p\n",
    "    \n",
    "    return con_ent\n",
    "\n",
    "def info_gain(feature,label) -> float:\n",
    "    \"\"\"\n",
    "    param feature : an m*1 np.array which contains one feature with different numbers\n",
    "    param label : an m*1 np.array ,the Y\n",
    "    \"\"\"\n",
    "    con_ent = conditional_entropy(feature,label)\n",
    "    ent = entropy(label)\n",
    "    return ent - con_ent\n",
    "\n",
    "class DecisionNode(object):\n",
    "    \"\"\"\n",
    "    The node of the decision tree\n",
    "    \"\"\"\n",
    "    def __init__(self,col=-1,data_set=None,labels=None,results=None,tb=None,fb=None):\n",
    "        self.has_calc_index = []    #已计算过的特征索引\n",
    "        self.col = col              #待检验的列索引 \n",
    "        self.data_set = data_set    #节点的待检测数据\n",
    "        self.labels = labels        #对应当前列匹配的值\n",
    "        self.results = results      #保存针对当前分支的结果，有值说明为叶子节点\n",
    "        self.tb = tb                #当前信息增益最高为True时的特征的子树\n",
    "        self.fb = fb                #当前信息增益最高为False时的特征的子树\n",
    "\n",
    "def if_split_end(label) -> bool:\n",
    "    \"\"\"\n",
    "    If splited in only one result , then stop\n",
    "    \"\"\"\n",
    "    length = len(label)\n",
    "    return length == 1\n",
    "\n",
    "def choose_best_feature(features,label,ignore_index) -> int:\n",
    "    \"\"\"\n",
    "    param features : a m*n np.array,where n is the num of features\n",
    "    param label : the Y\n",
    "    param ignore_index : the index list of calculated features\n",
    "    \"\"\"\n",
    "    n = features.shape[1]\n",
    "    entropy_dict = {}\n",
    "    \n",
    "    for i in range(n):\n",
    "        if i in ignore_index:\n",
    "            continue\n",
    "        entropy_dict[i] = info_gain(features[:,i],label)\n",
    "    \n",
    "    ret = sorted(entropy_dict.items(),key=lambda x:x[1],reverse=True)\n",
    "    return ret[0][0]\n",
    "\n",
    "class DecisionTree(object):\n",
    "    \"\"\"\n",
    "    Build a decision tree\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.feature_num = 0\n",
    "        self.tree_root = None\n",
    "    \n",
    "    def build_tree(self,node:DecisionNode):\n",
    "        \"\"\"\n",
    "        param node : a DecisionNode class\n",
    "        \"\"\"\n",
    "        if if_split_end(node.labels):\n",
    "            node.results = node.labels[0]\n",
    "            return\n",
    "        \n",
    "        best_index = choose_best_feature(node.data_set,node.labels,node.has_calc_index)\n",
    "        node.col = best_index\n",
    "        \n",
    "        #由最大信息增益划分\n",
    "        #左子树\n",
    "        tb_index = [i for i,value in enumerate(node.data_set) if value[best_index]]\n",
    "        tb_data_set = node.data_set[tb_index,:]\n",
    "        tb_label = node.labels[tb_index]\n",
    "        tb_node = DecisionNode(date_set=tb_data_set,labels=tb_label)\n",
    "        tb_node.has_calc_index = list(node.has_calc_index)\n",
    "        tb_node.has_calc_index.append(best_index)\n",
    "        node.tb = tb_node\n",
    "        \n",
    "        #右子树\n",
    "        fb_index = [i for i,value in enumerate(node.data_set) if not value[best_index]]\n",
    "        fb_data_set = node.data_set[fb_index,:]\n",
    "        fb_label = node.labels[fb_index]\n",
    "        fb_node = DecisionNode(data_set=fb_data_set,labels=fb_label)\n",
    "        fb_node.has_calc_index = list(node.has_calc_index)\n",
    "        fb_node.has_calc_index.append(best_index)\n",
    "        node.fb = fb_node\n",
    "        \n",
    "        if tb_index:\n",
    "            self.build_tree(node.tb)\n",
    "        if fb_index:\n",
    "            self.build_tree(node.fb)\n",
    "    def clear_tree_example_data(self,node:DecisionNode):\n",
    "        \"\"\"\n",
    "        clear training data of the tree\n",
    "        \"\"\"\n",
    "        del node.has_calc_index\n",
    "        del node.data_set\n",
    "        del node.labels\n",
    "        if node.tb:\n",
    "            self.clear_tree_example_data(node)\n",
    "        if node.fb:\n",
    "            self.clear_tree_example_data(node)\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        \"\"\"\n",
    "        param X : input training data X\n",
    "        param y : input training result y\n",
    "        \"\"\"\n",
    "        self.feature_num = len(X[0,:])\n",
    "        self.tree_root = DecisionNode(data_set=X,labels=y)\n",
    "        self.build_tree(self.tree_root)\n",
    "        self.clear_tree_example_data(self.tree_root)\n",
    "    \n",
    "    def _predict(self,data_test,node):\n",
    "        \"\"\"\n",
    "        param data_test : input test set testX\n",
    "        param node : the DecisionNode rooted from tree_root\n",
    "        \"\"\"\n",
    "        if node.results:\n",
    "            return node.results\n",
    "        col = node.col\n",
    "        if data_test[col]:\n",
    "            return self._predict(data_test,node.tb)\n",
    "        else:\n",
    "            return self._predict(data_test,node.fb)\n",
    "    \n",
    "    def predict(self,data_test):\n",
    "        \"\"\"\n",
    "        to predict\n",
    "        param data_test : test set testX\n",
    "        \"\"\"\n",
    "        return self._predict(data_test,self.tree_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i,value in enumerate(a) if value[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47738562622110958"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conditional_entropy(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
